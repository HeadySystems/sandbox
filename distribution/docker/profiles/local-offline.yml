# Local Offline â€” Everything on-device, zero cloud calls
# Usage: docker compose -f base.yml -f profiles/local-offline.yml up

services:
  heady-api:
    environment:
      - CLOUD_MODELS_ENABLED=false
      - REQUIRE_INTERNET=false

  model-runner:
    # Ollama runs fully local models
    environment:
      - OLLAMA_MODELS=llama3.1:8b,nomic-embed-text

  heady-orchestrator:
    environment:
      - PREFER_LOCAL_MODELS=true
      - CLOUD_FALLBACK=false

  heady-rag:
    environment:
      - EMBEDDINGS_LOCAL=true

  # Disable cloud-only services
  billing:
    profiles: ["disabled"]
  telemetry:
    profiles: ["disabled"]
